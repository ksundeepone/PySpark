{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af6fe516",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/20 01:08:40 WARN Utils: Your hostname, Sundeeps-MacBook-Air.local resolves to a loopback address: 127.0.0.1; using 11.38.254.137 instead (on interface en0)\n",
      "23/10/20 01:08:40 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/10/20 01:08:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/10/20 01:08:42 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession \n",
    "spark = SparkSession.builder.appName('Missing data').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3eaddc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv('/Users/sundeepk/Desktop/Employees.csv', header = True, inferSchema = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3505bb14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+-----------+------+\n",
      "|  name| age|experience |salary|\n",
      "+------+----+-----------+------+\n",
      "|Krish |  31|         10|  3000|\n",
      "| Sudha|  30|          8| 25000|\n",
      "| sunny|  27|          3| 20000|\n",
      "|  paul|  24|          1| 20000|\n",
      "|Harsha|  21|          1| 15000|\n",
      "|Shubam|  23|          2| 18000|\n",
      "|mahesh|NULL|       NULL| 40000|\n",
      "|  NULL|  34|         10|  NULL|\n",
      "|  NULL|  23|       NULL|  NULL|\n",
      "+------+----+-----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f74ffc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+-----------+------+\n",
      "|  name|age|experience |salary|\n",
      "+------+---+-----------+------+\n",
      "|Krish | 31|         10|  3000|\n",
      "| Sudha| 30|          8| 25000|\n",
      "| sunny| 27|          3| 20000|\n",
      "|  paul| 24|          1| 20000|\n",
      "|Harsha| 21|          1| 15000|\n",
      "|Shubam| 23|          2| 18000|\n",
      "+------+---+-----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Drops every row which has NULL\n",
    "\n",
    "df.na.drop().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1150e440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+-----------+------+\n",
      "|  name| age|experience |salary|\n",
      "+------+----+-----------+------+\n",
      "|Krish |  31|         10|  3000|\n",
      "| Sudha|  30|          8| 25000|\n",
      "| sunny|  27|          3| 20000|\n",
      "|  paul|  24|          1| 20000|\n",
      "|Harsha|  21|          1| 15000|\n",
      "|Shubam|  23|          2| 18000|\n",
      "|mahesh|NULL|       NULL| 40000|\n",
      "+------+----+-----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Drops Null values only from that Subset\n",
    "\n",
    "df.na.drop(how = 'all', subset= ['name']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eeb64143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+-----------+------+\n",
      "|  name|age|experience |salary|\n",
      "+------+---+-----------+------+\n",
      "|Krish | 31|         10|  3000|\n",
      "| Sudha| 30|          8| 25000|\n",
      "| sunny| 27|          3| 20000|\n",
      "|  paul| 24|          1| 20000|\n",
      "|Harsha| 21|          1| 15000|\n",
      "|Shubam| 23|          2| 18000|\n",
      "+------+---+-----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##Threshold \n",
    "\n",
    "#What is threshold =2 \n",
    "#--> it means drop only if there are 2 non-NULL values in that row\n",
    "\n",
    "df.na.drop(how = 'all', thresh = 3).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "947e0cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+-----------+------+\n",
      "|  name| age|experience |salary|\n",
      "+------+----+-----------+------+\n",
      "|Krish |  31|         10|  3000|\n",
      "| Sudha|  30|          8| 25000|\n",
      "| sunny|  27|          3| 20000|\n",
      "|  paul|  24|          1| 20000|\n",
      "|Harsha|  21|          1| 15000|\n",
      "|Shubam|  23|          2| 18000|\n",
      "|mahesh|NULL|       NULL| 40000|\n",
      "|  NULL|  34|         10|  NULL|\n",
      "|  NULL|  23|       NULL|  NULL|\n",
      "+------+----+-----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Fill the missing values \n",
    "\n",
    "df.na.fill('Missing', ['age']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2d4fb115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+-----------+------+\n",
      "|  name| age|experience |salary|\n",
      "+------+----+-----------+------+\n",
      "|Krish |  31|         10|  3000|\n",
      "| Sudha|  30|          8| 25000|\n",
      "| sunny|  27|          3| 20000|\n",
      "|  paul|  24|          1| 20000|\n",
      "|Harsha|  21|          1| 15000|\n",
      "|Shubam|  23|          2| 18000|\n",
      "|mahesh|NULL|       NULL| 40000|\n",
      "|  NULL|  34|         10|  NULL|\n",
      "|  NULL|  23|       NULL|  NULL|\n",
      "+------+----+-----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d97e00cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean of experience \n",
    "#LETS USE IMPUTER FUNCTION \n",
    "\n",
    "from pyspark.ml.feature import Imputer\n",
    "\n",
    "imputer = Imputer(\n",
    "        inputCols = ['age', 'experience ', 'salary'],\n",
    "        outputCols = [\"{}_imputed\".format(c) for c in ['age', 'experience ', 'salary']]\n",
    "        ).setStrategy(\"median\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f1b7c385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+-----------+------+-----------+-------------------+--------------+\n",
      "|  name| age|experience |salary|age_imputed|experience _imputed|salary_imputed|\n",
      "+------+----+-----------+------+-----------+-------------------+--------------+\n",
      "|Krish |  31|         10|  3000|         31|                 10|          3000|\n",
      "| Sudha|  30|          8| 25000|         30|                  8|         25000|\n",
      "| sunny|  27|          3| 20000|         27|                  3|         20000|\n",
      "|  paul|  24|          1| 20000|         24|                  1|         20000|\n",
      "|Harsha|  21|          1| 15000|         21|                  1|         15000|\n",
      "|Shubam|  23|          2| 18000|         23|                  2|         18000|\n",
      "|mahesh|NULL|       NULL| 40000|         24|                  3|         40000|\n",
      "|  NULL|  34|         10|  NULL|         34|                 10|         20000|\n",
      "|  NULL|  23|       NULL|  NULL|         23|                  3|         20000|\n",
      "+------+----+-----------+------+-----------+-------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "imputer.fit(df).transform(df).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0401a74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46b8335",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565a1a7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d89b39c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f846d4b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3359ad92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01dd109",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
